* ê°œì¸ì ì¸ ê³µë¶€ë¥¼ ìœ„í•´ ì¶œì²˜ í‘œê¸° í›„ ì‘ì„±í•©ë‹ˆë‹¤!

### Tensorflow 
- Tensor : ë‹¤ì°¨ì› ë°°ì—´ (Multi-dimensional Array)
- íŠ¹ì§•ì„ ì¶”ì¶œí•´ì£¼ëŠ” [Convoulution layer](https://tykimos.github.io/2017/01/27/CNN_Layer_Talk/)


##### [Tensor ê¸°ë³¸](https://codetorial.net/tensorflow/basics_of_tensor.html)
```python
a = tf.constant(1) # constantëŠ” ìƒìˆ˜ í…ì„œë¥¼ ë§Œë“¬
b = tf.constant([2,3])
print(a) # tf.Tensor(1, shape=(), dtype=int32)
print(b) # tf.Tensor([2,3], shape=(2,),dtype=int32)

c = tf.zeros([2, 3]) #zeroëŠ” 0ìœ¼ë¡œ ì±„ì›Œì§„ tensor ë§Œë“¬ / onesëŠ” 1ë¡œ ì±„ì›Œì§„ tensor ë§Œë“¬
print(c)
tf.Tensor([[0. 0. 0.][0. 0. 0.]], shape=(2, 3), dtype=float32)
print(a.dtype, a.shape) # <dtype: 'int32'> ìë£Œí˜• ë°˜í™˜
```
-------------------------------

### 0. ë°ì´í„° ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°
### 1. ë°ì´í„° ì…‹ ì „ì²˜ë¦¬
### 2. [Keras Sequential](http://blog.daum.net/sualchi/13720852)
###### [modelìƒì„±](https://ebbnflow.tistory.com/128?category=738689)
- Sequential API : ë‹¨ìˆœí•œ ì¸µ ìŒ“ê¸° ê°€ëŠ¥, ì§ê´€ì  
- Functional API : ë³µì¡í•œ ì¸µ ìŒ“ê¸° ê°€ëŠ¥

    + Kerasì˜ Sequential ëª¨ë¸ì€ ë ˆì´ì–´ë“¤ì˜ ì„ í˜• ìŠ¤íƒ(a linear stack of layers)ë¡œ ë˜ì–´ìˆìŒ
    
    ```python
    # modelì— ìƒì„±
    from keras.models import Sequential
    from keras.layers import Dense, Activation
    model = Sequential([
    Dense(32, input_shape=(784,)), # í´ë˜ìŠ¤32
    Activation('relu'),             # ì„ í˜• í•¨ìˆ˜
    Dense(10),                       # í´ë˜ìŠ¤ 10
    Activation('softmax'),])
    
    # add() í™œìš© ê³„ì¸µ ì¶”ê°€
    model = Sequential()
    model.add(Dense(32, input_dim=784))
    model.add(Activation('relu'))
    model.add(Dense(10, input_dim=32)) #
    model.add(Activation('softmax'))    #
    ```
##### [ğŸ¥‘Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense?hl=ko)
- model.add(Dense(50, kernel_initializer='he_normal')) : he_normal :: It draws samples from a truncated normal distribution centered on 0 with stddev = sqrt(2 / fan_in) where fan_in is the number of input units in the weight tensor.
- model.add(layers.Flatten()) : 
- model.add(Activation('sigmoid')) : activation í•¨ìˆ˜ ì´ê±° ì“°ê² ë‹¤~
##### [ğŸ‡initializers](https://www.tensorflow.org/api_docs/python/tf/keras/initializers/HeNormal)

### 3. [tf.keras.models.Sequential.compile](https://www.tensorflow.org/api_docs/python/tf/keras/Model)

 ```python
        compile( optimizer='rmsprop', loss=None, metrics=None, loss_weights=None,
         weighted_metrics=None, run_eagerly=None, steps_per_execution=None, **kwargs)
 ```
 
- optimizer :ìµœì í™”ëª¨ë¸ Adadelta, Adagrad, Adam, Adamax, Ftrl, Nadam, Optimizer, RMSprop, SGD
- loss : 
- metrics :
- loss_weights : 
- weighted_metrics : 
- run_eagerly :
- steps_per_execution
- **kwargs : 

### 4. [tf.keras.models.Sequential.fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model)
- ì˜¤ì°¨ì—­ì „íŒŒê°€ ì§„í–‰! loss functionì˜ gradientê°€ ì—­ì „íŒŒ > ê·¸ gradientë¥¼ ê°€ì§€ê³  ëª¨ë¸ì—ê²Œ ë§ëŠ” ìµœì ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸ í•˜ëŠ” ë¶€ë¶„!



-----------------------------------
