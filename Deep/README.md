*ê°œì¸ì ì¸ ê³µë¶€ë¥¼ ëª©ì ìœ¼ë¡œ ì¶œì²˜ í‘œê¸° í›„ ì‘ì„±í•˜ì˜€ìŠµë‹ˆë‹¤.

----------------------------------------------------------------
    
#### ìš©ì–´ì •ë¦¬

- Under fitting : í•™ìŠµë°ì´í„°ê°€ ëª¨ìë¼ê±°ë‚˜, í•™ìŠµì´ ì œëŒ€ë¡œ ë˜ì§€ ì•ŠëŠ” ê²ƒ, íŠ¸ë ˆì´ë‹ ë°ì´í„°ì— ê°€ê¹ê²Œ ê°€ì§€ ëª» í•˜ëŠ” ê²½ìš°

- Over fitting : íŠ¸ë ˆì´ë‹ ë°ì´í„°ì— ê·¸ë˜í”„ê°€ ë„ˆë¬´ ì •í™•íˆ ë§ì•„ë“¤ì–´ê°ˆ ë•Œ, ìƒ˜í”Œ ë°ì´í„°ì— ë„ˆë¬´ ì •í™•íˆ í•™ìŠµë˜ì–´ ìˆëŠ” ê²½ìš°
    + over fitting sol ) ì¶©ë¶„í•œ íŠ¸ë ˆì´ë‹ ë°ì´í„°ë¥¼ ì¤€ë¹„í•œë‹¤ / í”¼ì²˜ ìˆ˜ë¥¼ ì¤„ì¸ë‹¤ / regularizationì •ê·œí™”ë¥¼ í•œë‹¤!<br>
    
ğŸ [batchì™€ epoch](https://bskyvision.com/803)
- batch : ì§‘ë‹¨í•œ ë¬´ë¦¬, í•œíšŒë¶„ì„ ë¬¶ë‹¤ > ë”¥ëŸ¬ë‹ì—ì„œëŠ” ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ í•œë²ˆ ì—…ë°ì´íŠ¸ ì‹œí‚¬ ë•Œ ì‚¬ìš©ë˜ëŠ” ìƒ˜í”Œë“¤ì˜ ë¬¶ìŒ
    ex) 1000ê°œ ìƒ˜í”Œ ì¤‘ ë°°ì¹˜ ì‚¬ì´ì¦ˆê°€ 20ì´ë¼ë©´ 20ê°œì˜ ìƒ˜í”Œ ë‹¨ìœ„ë§ˆë‹¤ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ í•œë²ˆì”© ì—…ë°ì´íŠ¸ ì‹œí‚¨ë‹¤ëŠ” ë§, ì¦‰ 50ë²ˆ ê°€ì¤‘ì¹˜ê°€ ì—…ë°ì´íŠ¸ ëœë‹¤ëŠ” ë§!!!! í•˜ë‚˜ì˜ ë°ì´í„° ì…‹ì„ 50ê°œì˜ ë°°ì¹˜ë¡œ ë‚˜ëˆ ì„œ í›ˆë ¨ì„ ì§„í–‰í–ˆë‹¤ê³  ë³´ë©´ ë¨
- epoch : ì¤‘ìš”í•œ ì‚¬ê±´, ë³€í™”ë“¤ì´ ì¼ì–´ë‚œ ì‹œëŒ€! > ë”¥ëŸ¬ë‹ì—ì„œ ì—í¬í¬ëŠ” í•™ìŠµì˜ íšŸìˆ˜ë¥¼ ì˜ë¯¸í•œë‹¤ ex) epoch 10, batch 20 ê°€ì¤‘ì¹˜ë¥¼ 50ë²ˆ ì—…ë°ì´íŠ¸ í•˜ëŠ” ê²ƒì„ ì´ 10ë²ˆ ë°˜ë³µí•œë‹¤ëŠ”!! ê° ë°ì´í„° ìƒ˜í”Œì´ ì´ 10ë²ˆì”© ì‚¬ìš©ë˜ëŠ” ê²ƒì´ë‹¤! ê²°ê³¼ì ìœ¼ë¡œ 50 * 10 = 500ë²ˆ ì—…ë°ì´íŠ¸
-------
### Tensorflow 
- Tensor : ë‹¤ì°¨ì› ë°°ì—´ (Multi-dimensional Array)
- íŠ¹ì§•ì„ ì¶”ì¶œí•´ì£¼ëŠ” [Convoulution layer](https://tykimos.github.io/2017/01/27/CNN_Layer_Talk/)
1. [Keras Sequential](http://blog.daum.net/sualchi/13720852)
    + Kerasì˜ Sequential ëª¨ë¸ì€ ë ˆì´ì–´ë“¤ì˜ ì„ í˜• ìŠ¤íƒ(a linear stack of layers)ë¡œ ë˜ì–´ìˆìŒ
    ```python
    # modelì— ìƒì„±
    from keras.models import Sequential
    from keras.layers import Dense, Activation
    model = Sequential([
    Dense(32, input_shape=(784,)), # í´ë˜ìŠ¤32
    Activation('relu'),             # ì„ í˜• í•¨ìˆ˜
    Dense(10),                       # í´ë˜ìŠ¤ 10
    Activation('softmax'),])
    
    # add() í™œìš© ê³„ì¸µ ì¶”ê°€
    model = Sequential()
    model.add(Dense(32, input_dim=784))
    model.add(Activation('relu'))
    model.add(Dense(10, input_dim=32)) #
    model.add(Activation('softmax'))    #
    ```
2. [tf.keras.models.Sequential.compile](https://www.tensorflow.org/api_docs/python/tf/keras/Model)
```python
compile(
    optimizer='rmsprop', loss=None, metrics=None, loss_weights=None,
    weighted_metrics=None, run_eagerly=None, steps_per_execution=None, **kwargs
)
```
    - optimizer :ìµœì í™”ëª¨ë¸ Adadelta, Adagrad, Adam, Adamax, Ftrl, Nadam, Optimizer, RMSprop, SGD
    - loss : 
    - metrics :
    - loss_weights : 
    - weighted_metrics : 
    - run_eagerly :
    - steps_per_execution
    - **kwargs : 


###### [modelìƒì„±](https://ebbnflow.tistory.com/128?category=738689)
- Sequential API : ë‹¨ìˆœí•œ ì¸µ ìŒ“ê¸° ê°€ëŠ¥, ì§ê´€ì  
- Functional API : ë³µì¡í•œ ì¸µ ìŒ“ê¸° ê°€ëŠ¥
##### [Tensor ê¸°ë³¸](https://codetorial.net/tensorflow/basics_of_tensor.html)
```python
a = tf.constant(1) # constantëŠ” ìƒìˆ˜ í…ì„œë¥¼ ë§Œë“¬
b = tf.constant([2,3])
print(a) # tf.Tensor(1, shape=(), dtype=int32)
print(b) # tf.Tensor([2,3], shape=(2,),dtype=int32)

c = tf.zeros([2, 3]) #zeroëŠ” 0ìœ¼ë¡œ ì±„ì›Œì§„ tensor ë§Œë“¬ / onesëŠ” 1ë¡œ ì±„ì›Œì§„ tensor ë§Œë“¬
print(c)
tf.Tensor([[0. 0. 0.][0. 0. 0.]], shape=(2, 3), dtype=float32)
print(a.dtype, a.shape) # <dtype: 'int32'> ìë£Œí˜• ë°˜í™˜
```
##### [Numpyí•¨ìˆ˜](https://codetorial.net/numpy/functions/index.html)


##### [ğŸ‡initializers](https://www.tensorflow.org/api_docs/python/tf/keras/initializers/HeNormal)
##### [ğŸ¥‘Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense?hl=ko)
- model.add(Dense(50, kernel_initializer='he_normal')) : he_normal :: It draws samples from a truncated normal distribution centered on 0 with stddev = sqrt(2 / fan_in) where fan_in is the number of input units in the weight tensor.

- model.add(Activation('sigmoid'))
-----------------------------------


0. Neural Network
- ì¸ê°„ì˜ ë‡Œë¥¼ ëª¨ë°©í•˜ì—¬ ë§Œë“  ê²ƒ
- Input * Weight -- activation function-->output
- Back propagation(ì—­ì „íŒŒ) : trainnigì„ í†µí•´ weightë¥¼ ê²°ì •í•´ì£¼ëŠ” ê²ƒ
  
1. Activation Function
```
- step function
- sigmoid function
- tanh
- [ReLU](www.naver.com)
- Softmax function : multiclass classification ë¬¸ì œì—ì„œ ë§ì´ ì‚¬ìš©
```
  2) Hyperparameter
  ```
    - learning rate : ì˜¤ì°¨ë¥¼ í•™ìŠµì— ì–¼ë§ˆë‚˜ ë°˜ì˜í•  ì§€![learning rate]()
    - cost function
      + Mean square Error (í‰ê· ì œê³±ì˜¤ì°¨)
      + Cross-Entropy Error(êµì°¨ ì—”íŠ¸ë¡œí”¼ ì˜¤ì°¨)
    - Regularization parameter(ì •ê·œí™”)
    - Mini-batch í¬ê¸°
    - Training ë°˜ë³µ íšŸìˆ˜ : Training íšŸìˆ˜ ë„ˆë¬´ ë§ìœ¼ë©´ overfitting 
    - Hidden unit ê°œìˆ˜ : ë§ìœ¼ë©´ ë„¤íŠ¸ì›Œí¬ í‘œí˜„ë ¥ ë„“ì–´ì ¸ì„œ ì¢‹ì€ ì„±ëŠ¥ ë‚¼ ìˆ˜ë„ ìˆì§€ë§Œ, overfitting ë  ìˆ˜ë„ ìˆìŒ ì ìœ¼ë©´ underfitting
    - Weight intialization(ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”) : ëª¨ë“  ì´ˆê¸° ê°’ì„ 0ìœ¼ë¡œ ì„¤ì •í–ˆì„ ë–„ ëª¨ë“  ë‰´ëŸ°ì´ ë™ì¼í•œ ê²°ê³¼ë¥¼ ë‚´ì–´, Back propagation ê³¼ì •ì—ì„œ ë™ì¼í•œ gradient ê°’ì„ ì–»ëŠ”ë‹¤. ê·¸ë ‡ê²Œ ë˜ë©´ ëª¨ë“  íŒŒë¼ë¯¸í„°ê°€ ë™ì¼í•œ ê°’ìœ¼ë¡œ update ë˜ì–´ ë‰´ëŸ°ì˜ ê°œìˆ˜ê°€ ì˜ë¯¸ê°€ ì—†ì–´ì§ *ê°€ì¤‘ì¹˜ëŠ” ë³´í†µ ì…ë ¥ ë°ì´í„° ìˆ˜ë¥¼ nìœ¼ë¡œ ë‘˜ ë•Œ +1/sqrt(n) ~ -1/sqrt(n)ì•ˆì—ì„œ ëœë¤ìœ¼ë¡œ ê²°ì •í•¨ 
  ```
  3) Hyperparameter optimization
  ```
    - Grid Search
    - Random search
    - Bayesian optimization
  ```

2. [CNNì´ë€](https://velog.io/@tmddn0311/CNN-tutorial)
- Fully connectedì™€ ì°¨ì´ì 

- Input
```
    1) Feature extraction : íŠ¹ì§•ì„ ì¶”ì¶œí•˜ê¸° ìœ„í•œ ë‹¨ê³„
    2) Shift and distortion invariance : topology ë³€í™”ì— ì˜í–¥ì„ ë°›ì§€ ì•Šë„ë¡ í•´ì£¼ëŠ” ë‹¨ê³„
    3) Classification : ë¶„ë¥˜ê¸°
```
- Output
    
    
- Filterë€ ? 
    + íŠ¹ì§•ì´ ë°ì´í„°ì— ìˆëŠ”ì§€ ì—†ëŠ”ì§€ ê²€ì¶œí•´ ì£¼ëŠ” í•¨ìˆ˜
    + ê°ê¸°ë‹¤ë¥¸ íŠ¹ì§•ë“¤ì„ ê²€ì¶œí•´ ì¤„ ìˆ˜ ìˆëŠ” ê²ƒ

- Stride : í•„í„°ë¥¼ ì ìš©í•˜ëŠ” ê°„ê²©

- Kernel : í•œë²ˆì— ì²˜ë¦¬í•  ë…¸ë“œì˜ í¬ê¸°

optimizer
- SGD : Stochastic Gradient Descent í™•ë¥ ì  ê²½ì‚¬í•˜ê°•ë²•
- adam



  
[ì°¸ê³ í•œ ìë£Œ]  
- [ë¨¸ì‹ ëŸ¬ë‹ê°œìš”](https://m.blog.naver.com/laonple/221166694845)
- [AlexNet](https://bskyvision.com/421)
- [ì¡°ëŒ€í˜‘ë‹˜ ë¸”ë¡œê·¸](https://bcho.tistory.com/1149)
- [humkim git](https://github.com/hunkim/DeepLearningZeroToAll)
- [ëª¨ë‘ì˜ ë”¥ëŸ¬ë‹2](https://www.youtube.com/watch?v=qPMeuL2LIqY&list=PLQ28Nx3M4Jrguyuwg4xe9d9t2XE639e5C&index=2)
- [ëª¨ë‘ì˜ ë”¥ëŸ¬ë‹ ê¹ƒí—ˆë¸Œ](https://github.com/hunkim/DeepLearningZeroToAll/tree/master/tf2)
- [ë¼ì˜¨í”¼í”Œë”¥ëŸ¬ë‹ ê°œìš”](https://blog.naver.com/PostView.nhn?blogId=laonple&logNo=220608018546)
- [AI note](https://github.com/SeonminKim1/AI_Notes)
[1][tensorflow good](https://codetorial.net/tensorflow/basics_of_optimizer.html)<br>
[2][Deep ê°œë…](https://excelsior-cjh.tistory.com/79)<br>
[3][ê¹€íƒœì˜ì˜ì¼€ë¼ìŠ¤ :ì¼€ë¼ìŠ¤ê¸°ë³¸ê°œë…](https://tykimos.github.io/lecture/)<br>
[4][ë‚˜ì¤‘ì— ë”°ë¼í•´](https://www.edwith.org/deeplearningai4/lecture/34895)<br>
[5][one-shot learingì„¤ëª…](https://medium.com/mathpresso/%EC%83%B4-%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EC%9D%B4%EB%AF%B8%EC%A7%80-%EA%B2%80%EC%83%89%EA%B8%B0%EB%8A%A5-%EB%A7%8C%EB%93%A4%EA%B8%B0-f2af4f9e312a)<br>
[6][One-shot ë°œí‘œ](http://dsba.korea.ac.kr/seminar/?mod=document&uid=63)<br>
[7][ë°‘ë°”ë‹¥ ë¶€í„° ì‹œì‘í•˜ëŠ” ë”¥ëŸ¬ë‹](https://velog.io/@jakeseo_me/%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D-2-2-MNIST-%EC%86%90%EA%B8%80%EC%94%A8-%EC%88%AB%EC%9E%90-%EC%9D%B8%EC%8B%9D)<br>
[8][ì„±ëŠ¥ í‰ê°€ê¹Œì§€ ì™„ë²½](https://velog.io/@tmddn0311/mnist-classification)<br>
[][Keras API/ì„ í˜•íšŒê·€,ë¡œì§€ìŠ¤í‹±,ë‹¤ì¤‘ì…ë ¥ ì˜ˆì œ](https://wikidocs.net/38861)<br>
[][Keras Docs](https://keras.io/ko/optimizers/)<br>
[][ê°„ë‹¨í•œ ë™ì˜ìƒ](https://www.youtube.com/watch?v=VWFPlPYxzNg&list=PLVNY1HnUlO2702hhjCldVCwKiudLHhPG0)<br>
[][ì•™ìƒë¸”ë¶€í„° ë³´ê¸°](https://ebbnflow.tistory.com/133)<br>
[][ì•™ìƒë¸” ì •ë¦¬](https://teddylee777.github.io/scikit-learn/scikit-learn-ensemble)<br>
[][tensorflow DQN](https://github.com/devsisters/DQN-tensorflow/)<br>
[][ì˜¤ì°¨ì—­ì „íŒŒì´ë¡ ](https://excelsior-cjh.tistory.com/171)<br>
[ì´ê±°ë‹¤!][Mnistì—¬ëŸ¬ê°€ì§€ëª¨ë¸ë¡œ ìµœì í™”](https://buomsoo-kim.github.io/keras/2018/04/22/Easy-deep-learning-with-Keras-4.md/)<br>



##### CNN
 - https://velog.io/@tmddn0311/CNN-tutorial
 - [CNN ì˜¤ì°¨ì—­ì „íŒŒ](https://ratsgo.github.io/deep%20learning/2017/04/05/CNNbackprop/)


[][markdown ì‚¬ìš©ë²•](https://steemit.com/kr/@buket47/emoji-2018-05-10)<br>
[][markdown ì´ëª¨í‹°ì½˜ ì¶œì²˜](http://www.iemoji.com/#?category=food-drink&version=36&theme=appl&skintone=default)<br>
[][sklearn](https://scikit-learn.org/stable/)<br>
[][Deep learning Image classification Guidebook](https://hoya012.github.io/blog/deeplearning-classification-guidebook-1/)
